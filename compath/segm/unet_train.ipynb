{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "UNet: train over patches of histopath images\n",
    "==="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from torch import nn\n",
    "from matplotlib import pyplot as plt\n",
    "from tqdm import tqdm, trange\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SegmentationDataSet3(data.Dataset):\n",
    "    \"\"\"Image segmentation dataset with caching, pretransforms and multiprocessing.\"\"\"\n",
    "    def __init__(self,\n",
    "                 inputs: list,\n",
    "                 targets: list,\n",
    "                 transform=None,\n",
    "                 use_cache=False,\n",
    "                 pre_transform=None,\n",
    "                 ):\n",
    "        self.inputs = inputs\n",
    "        self.targets = targets\n",
    "        self.transform = transform\n",
    "        self.inputs_dtype = torch.float32\n",
    "        self.targets_dtype = torch.long\n",
    "        self.use_cache = use_cache\n",
    "        self.pre_transform = pre_transform\n",
    "\n",
    "        if self.use_cache:\n",
    "            from multiprocessing import Pool\n",
    "            from itertools import repeat\n",
    "\n",
    "            with Pool() as pool:\n",
    "                self.cached_data = pool.starmap(self.read_images, zip(inputs, targets, repeat(self.pre_transform)))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.inputs)\n",
    "\n",
    "    def __getitem__(self,\n",
    "                    index: int):\n",
    "        if self.use_cache:\n",
    "            x, y = self.cached_data[index]\n",
    "        else:\n",
    "            # Select the sample\n",
    "            input_ID = self.inputs[index]\n",
    "            target_ID = self.targets[index]\n",
    "\n",
    "            # Load input and target\n",
    "            x, y = imread(str(input_ID)), imread(str(target_ID))\n",
    "\n",
    "        # Preprocessing\n",
    "        if self.transform is not None:\n",
    "            x, y = self.transform(x, y)\n",
    "\n",
    "        # Typecasting\n",
    "        x, y = torch.from_numpy(x).type(self.inputs_dtype), torch.from_numpy(y).type(self.targets_dtype)\n",
    "\n",
    "        return x, y\n",
    "\n",
    "    @staticmethod\n",
    "    def read_images(inp, tar, pre_transform):\n",
    "        inp, tar = imread(str(inp)), imread(str(tar))\n",
    "        if pre_transform:\n",
    "            inp, tar = pre_transform(inp, tar)\n",
    "        return inp, tar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LearningRateFinder:\n",
    "    \"\"\"\n",
    "    Train a model using different learning rates within a range to find the optimal learning rate.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 model: nn.Module,\n",
    "                 criterion,\n",
    "                 optimizer,\n",
    "                 device\n",
    "                 ):\n",
    "        self.model = model\n",
    "        self.criterion = criterion\n",
    "        self.optimizer = optimizer\n",
    "        self.loss_history = {}\n",
    "        self._model_init = model.state_dict()\n",
    "        self._opt_init = optimizer.state_dict()\n",
    "        self.device = device\n",
    "\n",
    "    def fit(self,\n",
    "            data_loader: torch.utils.data.DataLoader,\n",
    "            steps=100,\n",
    "            min_lr=1e-7,\n",
    "            max_lr=1,\n",
    "            constant_increment=False\n",
    "            ):\n",
    "        \"\"\"\n",
    "        Trains the model for number of steps using varied learning rate and store the statistics\n",
    "        \"\"\"\n",
    "        self.loss_history = {}\n",
    "        self.model.train()\n",
    "        current_lr = min_lr\n",
    "        steps_counter = 0\n",
    "        epochs = math.ceil(steps / len(data_loader))\n",
    "\n",
    "        progressbar = trange(epochs, desc='Progress')\n",
    "        for epoch in progressbar:\n",
    "            batch_iter = tqdm(enumerate(data_loader), 'Training', total=len(data_loader),\n",
    "                              leave=False)\n",
    "\n",
    "            for i, (x, y) in batch_iter:\n",
    "                x, y = x.to(self.device), y.to(self.device)\n",
    "                for param_group in self.optimizer.param_groups:\n",
    "                    param_group['lr'] = current_lr\n",
    "                self.optimizer.zero_grad()\n",
    "                out = self.model(x)\n",
    "                loss = self.criterion(out, y)\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "                self.loss_history[current_lr] = loss.item()\n",
    "\n",
    "                steps_counter += 1\n",
    "                if steps_counter > steps:\n",
    "                    break\n",
    "\n",
    "                if constant_increment:\n",
    "                    current_lr += (max_lr - min_lr) / steps\n",
    "                else:\n",
    "                    current_lr = current_lr * (max_lr / min_lr) ** (1 / steps)\n",
    "\n",
    "    def plot(self,\n",
    "             smoothing=True,\n",
    "             clipping=True,\n",
    "             smoothing_factor=0.1\n",
    "             ):\n",
    "        \"\"\"\n",
    "        Shows loss vs learning rate(log scale) in a matplotlib plot\n",
    "        \"\"\"\n",
    "        loss_data = pd.Series(list(self.loss_history.values()))\n",
    "        lr_list = list(self.loss_history.keys())\n",
    "        if smoothing:\n",
    "            loss_data = loss_data.ewm(alpha=smoothing_factor).mean()\n",
    "            loss_data = loss_data.divide(pd.Series(\n",
    "                [1 - (1.0 - smoothing_factor) ** i for i in range(1, loss_data.shape[0] + 1)]))  # bias correction\n",
    "        if clipping:\n",
    "            loss_data = loss_data[10:-5]\n",
    "            lr_list = lr_list[10:-5]\n",
    "        plt.plot(lr_list, loss_data)\n",
    "        plt.xscale('log')\n",
    "        plt.title('Loss vs Learning rate')\n",
    "        plt.xlabel('Learning rate (log scale)')\n",
    "        plt.ylabel('Loss (exponential moving average)')\n",
    "        plt.show()\n",
    "\n",
    "    def reset(self):\n",
    "        \"\"\"\n",
    "        Resets the model and optimizer to its initial state\n",
    "        \"\"\"\n",
    "        self.model.load_state_dict(self._model_init)\n",
    "        self.optimizer.load_state_dict(self._opt_init)\n",
    "        print('Model and optimizer in initial state.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_training(training_losses,\n",
    "                  validation_losses,\n",
    "                  learning_rate,\n",
    "                  gaussian=True,\n",
    "                  sigma=2,\n",
    "                  figsize=(8, 6)\n",
    "                  ):\n",
    "    \"\"\"\n",
    "    Returns a loss plot with training loss, validation loss and learning rate.\n",
    "    \"\"\"\n",
    "\n",
    "    import matplotlib.pyplot as plt\n",
    "    from matplotlib import gridspec\n",
    "    from scipy.ndimage import gaussian_filter\n",
    "\n",
    "    list_len = len(training_losses)\n",
    "    x_range = list(range(1, list_len + 1))  # number of x values\n",
    "\n",
    "    fig = plt.figure(figsize=figsize)\n",
    "    grid = gridspec.GridSpec(ncols=2, nrows=1, figure=fig)\n",
    "\n",
    "    subfig1 = fig.add_subplot(grid[0, 0])\n",
    "    subfig2 = fig.add_subplot(grid[0, 1])\n",
    "\n",
    "    subfigures = fig.get_axes()\n",
    "\n",
    "    for i, subfig in enumerate(subfigures, start=1):\n",
    "        subfig.spines['top'].set_visible(False)\n",
    "        subfig.spines['right'].set_visible(False)\n",
    "\n",
    "    if gaussian:\n",
    "        training_losses_gauss = gaussian_filter(training_losses, sigma=sigma)\n",
    "        validation_losses_gauss = gaussian_filter(validation_losses, sigma=sigma)\n",
    "\n",
    "        linestyle_original = '.'\n",
    "        color_original_train = 'lightcoral'\n",
    "        color_original_valid = 'lightgreen'\n",
    "        color_smooth_train = 'red'\n",
    "        color_smooth_valid = 'green'\n",
    "        alpha = 0.25\n",
    "    else:\n",
    "        linestyle_original = '-'\n",
    "        color_original_train = 'red'\n",
    "        color_original_valid = 'green'\n",
    "        alpha = 1.0\n",
    "\n",
    "    # Subfig 1\n",
    "    subfig1.plot(x_range, training_losses, linestyle_original, color=color_original_train, label='Training',\n",
    "                 alpha=alpha)\n",
    "    subfig1.plot(x_range, validation_losses, linestyle_original, color=color_original_valid, label='Validation',\n",
    "                 alpha=alpha)\n",
    "    if gaussian:\n",
    "        subfig1.plot(x_range, training_losses_gauss, '-', color=color_smooth_train, label='Training', alpha=0.75)\n",
    "        subfig1.plot(x_range, validation_losses_gauss, '-', color=color_smooth_valid, label='Validation', alpha=0.75)\n",
    "    subfig1.title.set_text('Training & validation loss')\n",
    "    subfig1.set_xlabel('Epoch')\n",
    "    subfig1.set_ylabel('Loss')\n",
    "\n",
    "    subfig1.legend(loc='upper right')\n",
    "\n",
    "    # Subfig 2\n",
    "    subfig2.plot(x_range, learning_rate, color='black')\n",
    "    subfig2.title.set_text('Learning rate')\n",
    "    subfig2.set_xlabel('Epoch')\n",
    "    subfig2.set_ylabel('LR')\n",
    "\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def predict(img,\n",
    "            model,\n",
    "            preprocess,\n",
    "            postprocess,\n",
    "            device,\n",
    "            ):\n",
    "    model.eval()\n",
    "    img = preprocess(img)  # preprocess image\n",
    "    x = torch.from_numpy(img).to(device)  # to torch, send to device\n",
    "    with torch.no_grad():\n",
    "        out = model(x)  # send through model/network\n",
    "\n",
    "    out_softmax = torch.softmax(out, dim=1)  # perform softmax on outputs\n",
    "    result = postprocess(out_softmax)  # postprocess outputs\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from inference import predict\n",
    "from transformations import normalize_01, re_normalize\n",
    "from unet import UNet\n",
    "\n",
    "# root directory\n",
    "root = pathlib.Path.cwd() / 'Carvana' / 'Test'\n",
    "def get_filenames_of_path(path: pathlib.Path, ext: str = '*'):\n",
    "    \"\"\"Returns a list of files in a directory/path. Uses pathlib.\"\"\"\n",
    "    filenames = [file for file in path.glob(ext) if file.is_file()]\n",
    "    return filenames\n",
    "\n",
    "# input and target files\n",
    "images_names = get_filenames_of_path(root / 'Input')\n",
    "targets_names = get_filenames_of_path(root / 'Target')\n",
    "\n",
    "# read images and store them in memory\n",
    "images = [imread(img_name) for img_name in images_names]\n",
    "targets = [imread(tar_name) for tar_name in targets_names]\n",
    "\n",
    "# Resize images and targets\n",
    "images_res = [resize(img, (128, 128, 3)) for img in images]\n",
    "resize_kwargs = {'order': 0, 'anti_aliasing': False, 'preserve_range': True}\n",
    "targets_res = [resize(tar, (128, 128), **resize_kwargs) for tar in targets]\n",
    "\n",
    "# device\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    torch.device('cpu')\n",
    "\n",
    "# model\n",
    "model = UNet(in_channels=3,\n",
    "             out_channels=2,\n",
    "             n_blocks=4,\n",
    "             start_filters=32,\n",
    "             activation='relu',\n",
    "             normalization='batch',\n",
    "             conv_mode='same',\n",
    "             dim=2).to(device)\n",
    "\n",
    "\n",
    "model_name = 'carvana_model.pt'\n",
    "model_weights = torch.load(pathlib.Path.cwd() / model_name)\n",
    "\n",
    "model.load_state_dict(model_weights)\n",
    "\n",
    "# preprocess function\n",
    "def preprocess(img: np.ndarray):\n",
    "    img = np.moveaxis(img, -1, 0)  # from [H, W, C] to [C, H, W]\n",
    "    img = normalize_01(img)  # linear scaling to range [0-1]\n",
    "    img = np.expand_dims(img, axis=0)  # add batch dimension [B, C, H, W]\n",
    "    img = img.astype(np.float32)  # typecasting to float32\n",
    "    return img\n",
    "\n",
    "\n",
    "# postprocess function\n",
    "def postprocess(img: torch.tensor):\n",
    "    img = torch.argmax(img, dim=1)  # perform argmax to generate 1 channel\n",
    "    img = img.cpu().numpy()  # send to cpu and transform to numpy.ndarray\n",
    "    img = np.squeeze(img)  # remove batch dim and channel dim -> [H, W]\n",
    "    img = re_normalize(img)  # scale it to the range [0-255]\n",
    "    return img\n",
    "\n",
    "# predict the segmentation maps \n",
    "output = [predict(img, model, preprocess, postprocess, device) for img in images_res]"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
